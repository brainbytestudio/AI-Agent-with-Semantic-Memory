# ğŸ§ AI-Agent-with-Semantic-Memory
 
### Production-Ready AI Agent with Gemini, ChromaDB & Async Tool Calling

A production-style AI Agent that combines:

- ğŸ” Semantic Long-Term Memory (Vector DB)
- ğŸŒ Async Web Search Tool
- ğŸ¤– Gemini as Execution LLM
- ğŸ§  Intelligent Tool-Calling Architecture
- ğŸ“Š Phoenix Tracing for Observability
- ğŸ’¬ Gradio UI for Interaction

Unlike traditional chatbots that rely only on chat history, this system remembers information **by meaning**, not keywords.

---

## ğŸš€ Demo Architecture

User Query
â†“
Semantic Memory Search (ChromaDB)
â†“
Relevant Found? â”€â”€ Yes â”€â”€â–º Reuse Memory
â”‚
No
â†“
Async Web Search
â†“
Gemini Generates Final Answer
â†“
Store Clean Knowledge in Vector DB


Each message:
- Runs as a separate trace
- Grouped by conversation_id
- Fully observable via Phoenix

---

## ğŸ“¥ Installation Guide

### 1ï¸âƒ£ Install `uv` (Package Manager)

`uv` is a modern, ultra-fast Python package manager written in **Rust**.

#### Windows (PowerShell)

```powershell
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

#### macOS / Linux (Terminal)

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

> ğŸ’¡ macOS users can also install via Homebrew:

```bash
brew install uv
```

---

### 2ï¸âƒ£ Setup Project & Dependencies

Clone the repository and install all required dependencies using `uv`:

```bash
# Create a virtual environment
uv venv

# Install project dependencies
uv pip install --
```

---

## ğŸ” Environment Variables (.env)

Create a `.env` file in the project root and add your API keys:

```env
GEMINI_API_KEY=your_gemini_api_key_here
```

> ğŸ”’ These keys are loaded securely using `python-dotenv` and are **never hard-coded**.

---

## ğŸ— Project Structure
AI_Memory_Agent/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ app.py # Orchestrator + Gradio UI
â”‚ â”œâ”€â”€ my_agents.py # Agent Definition & Prompting
â”‚ â””â”€â”€ tools/
â”‚ â”œâ”€â”€ search.py # Async Web Search Tool
â”‚ â””â”€â”€ vector_ops.py # Semantic Memory Layer
â”‚
â”œâ”€â”€ conversation_memory/ # ChromaDB Persistent Storage
â”œâ”€â”€ .env # API Keys (Not committed)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## ğŸ§  Core Concepts Implemented

### 1ï¸âƒ£ Semantic Memory
- Sentence Transformers for embeddings
- ChromaDB for persistent vector storage
- Meaning-based similarity search
- Timestamp-aware reasoning

---

### 2ï¸âƒ£ Agent Tool Calling
- OpenAI Agents SDK
- Structured function tools
- LLM decides when to:
  - Call memory
  - Call web search
  - Generate final answer

---

### 3ï¸âƒ£ Async Execution
- Async web search using `asyncio.gather`
- Parallel search queries
- Non-blocking tool execution

---

### 4ï¸âƒ£ Observability (Phoenix)
- Auto-instrumented tracing
- Separate trace per user message
- Grouped via `conversation_id`
- Production-style debugging

---

## ğŸ›  Tech Stack

| Component | Technology |
|-----------|------------|
| LLM | Gemini (OpenAI-Compatible API) |
| Agent Framework | OpenAI Agents SDK |
| Vector Database | ChromaDB |
| Embeddings | SentenceTransformers (all-MiniLM-L6-v2) |
| Async Execution | asyncio |
| Tracing | Arize Phoenix |
| UI | Gradio |

---

## ğŸ”§ Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/yourusername/AI-Agent-with-Semantic-Memory.git
cd AI-Agent-with-Semantic-Memory

â­ If You Found This Useful

Give this repo a star â­
Follow for more advanced AI system builds ğŸš€
